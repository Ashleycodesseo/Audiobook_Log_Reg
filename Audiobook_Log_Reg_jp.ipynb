{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Goal: In this project we are trying to figure out which\n",
    "#Audiobook customer is most likely to buy again using Logistic Regression. \n",
    "# The data was gathered over 2 years. The targets was data gathered over\n",
    "#an additional 6 months, seeing who bought or didn't\n",
    "#buy in that time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import The Relevant Libraries\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the Raw Data\n",
    "raw_csv_data= pd.read_csv('Audiobooks-data_raw.csv')\n",
    "print(display(raw_csv_data.head(20)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=raw_csv_data.copy()\n",
    "print(display(df.head(20)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['ID'], axis=1)\n",
    "print(display(df.head()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate the Targets from the dataset\n",
    "inputs_all= df.loc[:,'Book length (mins)_overall':'Last visited minus Purchase date']\n",
    "targets_all= df['Targets']\n",
    "print(display(inputs_all.head()))\n",
    "print(display(targets_all.head()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffling the Data to prep for balancing\n",
    "shuffled_indices= np.arange(inputs_all.shape[0])\n",
    "np.random.shuffle(shuffled_indices)\n",
    "shuffled_inputs= inputs_all.iloc[shuffled_indices]\n",
    "shuffled_targets= targets_all[shuffled_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Balance the Dataset\n",
    "#There are significantly more 0's than 1's in our target.\n",
    "#We want a good accurate model\n",
    "print(inputs_all.shape)\n",
    "print(targets_all.shape)\n",
    "#%%\n",
    "num_one_targets= int(np.sum(targets_all))\n",
    "zero_targets_counter= 0\n",
    "indices_to_remove= []\n",
    "print(num_one_targets)\n",
    "#%%\n",
    "for i in range(targets_all.shape[0]):\n",
    "    if targets_all[i]==0:\n",
    "        zero_targets_counter +=1\n",
    "        if zero_targets_counter> num_one_targets:\n",
    "            indices_to_remove.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_all_balanced= inputs_all.drop(indices_to_remove,axis=0)\n",
    "targets_all_balanced= targets_all.drop(indices_to_remove,axis=0)\n",
    "targets_all_balanced= targets_all_balanced.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inputs_all_balanced.shape)\n",
    "print(targets_all_balanced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardizing the Inputs\n",
    "#We won't standardize the Reviews Column because they serve as a \n",
    "#categorical variable with a binary 0/1 signifier\n",
    "\n",
    "print(inputs_all_balanced.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unscaled_inputs= inputs_all_balanced.loc[:,['Book length (mins)_overall', 'Book length (mins)_avg', 'Price_overall',\n",
    " 'Price_avg', 'Review 10/10', 'Minutes listened', 'Completion',\n",
    " 'Support requests', 'Last visited minus Purchase date']]\n",
    "\n",
    "print(display(unscaled_inputs.head()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audiobook_scaler= StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audiobook_scaler.fit(unscaled_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_inputs= audiobook_scaler.transform(unscaled_inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(display(scaled_inputs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scaled_inputs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforming the scaled_inputs array back into a Dataframe\n",
    "scaled_inputs= pd.DataFrame(scaled_inputs, columns=['Book length (mins)_overall', 'Book length (mins)_avg',\n",
    "'Price_overall','Price_avg', 'Review 10/10','Minutes listened', 'Completion','Support requests',\n",
    "'Last visited minus Purchase date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(display(scaled_inputs.head()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(display(scaled_inputs.tail(25)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now adding the 'Review' column to the new scaled inputs Dataframe \n",
    "print(inputs_all_balanced['Review'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review= inputs_all_balanced['Review'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_inputs['Review']= review\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(display(scaled_inputs.head()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(display(scaled_inputs.tail(25)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scaled_inputs.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scaled_inputs.columns.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reorderd_columns= ['Book length (mins)_overall', 'Book length (mins)_avg', 'Price_overall',\n",
    " 'Price_avg', 'Review','Review 10/10', 'Minutes listened', 'Completion',\n",
    " 'Support requests', 'Last visited minus Purchase date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_inputs= scaled_inputs[reorderd_columns]\n",
    "print(display(scaled_inputs.head()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into Train and Test and Shuffle\n",
    "#Import relevant library\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_test_split(scaled_inputs, targets_all_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test= train_test_split(scaled_inputs, targets_all_balanced, train_size=0.8, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's see the shape of these arrays\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression with SKLearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the Model\n",
    "reg= LogisticRegression()\n",
    "reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the accuracy of the model\n",
    "reg.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manually Checking the Model Accuracy\n",
    "model_outputs= reg.predict(x_train)\n",
    "print(model_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_outputs== y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(model_outputs==y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_outputs.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum((model_outputs==y_train))/model_outputs.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the Intercept/Coefficients and Creating a Summary Table\n",
    "print(reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reg.coef_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scaled_inputs.columns.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name= scaled_inputs.columns.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_table= pd.DataFrame(columns=['Feature name'], data=feature_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_table['Coefficient']= np.transpose(reg.coef_)\n",
    "print(display(summary_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_table.index= summary_table.index+1\n",
    "summary_table.loc[0]= ['Intercept', reg.intercept_[0]]\n",
    "summary_table= summary_table.sort_index()\n",
    "print(display(summary_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interpreting the Coefficients\n",
    "summary_table['Odds_ratio']= np.exp(summary_table.Coefficient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(display(summary_table))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(display(summary_table.sort_values('Odds_ratio', ascending=False)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#So from the odds ratio table it shows that the\n",
    "#Avg Book Length, Avg Price, Whether customers left reviews\n",
    "#or sought customer support were the Strongest indicators of \n",
    "#Them Buying again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing the Model\n",
    "reg.score(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the Probability of an output\n",
    "predicted_proba= reg.predict_proba(x_test)\n",
    "print(predicted_proba)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predicted_proba.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predicted_proba[:,1])\n",
    "#If the probability is below 0.5 it gets a 0 and above 0.5, it gets a 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
